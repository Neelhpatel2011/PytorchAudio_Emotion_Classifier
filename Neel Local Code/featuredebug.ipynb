{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Neel Patel\\\\Documents\\\\Github Repositories\\\\PytorchAudio_Emotion_Classifier'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir(r'c:/Users/Neel Patel/Documents/Github Repositories/PytorchAudio_Emotion_Classifier')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "angry      254\n",
       "disgust    254\n",
       "fear       254\n",
       "happy      254\n",
       "sad        254\n",
       "neutral    249\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r'Data/metadata-and-augmentations/'\n",
    "SEED = 42\n",
    "#Get the validation features (unaugmented training 20%)\n",
    "val_training_df = pd.read_csv(data_path+'training_df.csv')\n",
    "\n",
    "#GET RID OF THE SURPRISED CATEGORY!\n",
    "val_training_df = val_training_df.loc[val_training_df['Emotion'] != 'surprised']\n",
    "\n",
    "#Get random 20% of this data with equal balance of emotions!\n",
    "#Function to sample 20% of data with equal balance of emotions\n",
    "def sample_balanced(df, fraction=0.2):\n",
    "    # Group by Emotion\n",
    "    grouped = df.groupby('Emotion')\n",
    "\n",
    "    # Sample fraction of each group and concatenate\n",
    "    sampled_df = grouped.apply(lambda x: x.sample(frac=fraction, random_state=SEED)).reset_index(drop=True)\n",
    "    return sampled_df\n",
    "\n",
    "# Get the validation dataset\n",
    "val_training_df = sample_balanced(val_training_df, fraction=0.2)\n",
    "\n",
    "val_training_df['Emotion'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000220D33ED910>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_training_df.groupby('Emotion').apply(lambda x: x.sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load metadatas for train,val,test\n",
    "metadata_train = np.load('Data/' + 'training_metadata_no_sur.npy',allow_pickle=True)\n",
    "metadata_val = np.load('Data/' + 'val_metadata_no_sur.npy',allow_pickle=True)\n",
    "#metadata_test = np.load('Data/' + 'test_metadata.npy', allow_pickle=True)\n",
    "\n",
    "#Load HDF5 format files \n",
    "train_hdf5_file = 'Data/training_data.hdf5'\n",
    "val_hdf5_file = 'Data/test_data.hdf5'\n",
    "#test_hdf5_file = 'Data/test_data.hdf5'\n",
    "\n",
    "train_metadata_df = pd.DataFrame(metadata_train)\n",
    "val_metadata_df = pd.DataFrame(metadata_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1007_IOM_NEU_XX_augmented_training_V1_1025.wav</td>\n",
       "      <td>augmented_training_samples/1007_IOM_NEU_XX_aug...</td>\n",
       "      <td>female</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DC_n20_augmented_training_V1_243.wav</td>\n",
       "      <td>augmented_training_samples/DC_n20_augmented_tr...</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1027_ITS_NEU_XX_augmented_training_V1_5727.wav</td>\n",
       "      <td>augmented_training_samples/1027_ITS_NEU_XX_aug...</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03-01-02-01-02-01-05_augmented_training_V1_167...</td>\n",
       "      <td>augmented_training_samples/03-01-02-01-02-01-0...</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1084_IEO_NEU_XX_augmented_training_V1_3757.wav</td>\n",
       "      <td>augmented_training_samples/1084_IEO_NEU_XX_aug...</td>\n",
       "      <td>female</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>1042_DFA_ANG_XX_augmented_training_V1_5556.wav</td>\n",
       "      <td>augmented_training_samples/1042_DFA_ANG_XX_aug...</td>\n",
       "      <td>male</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7594</th>\n",
       "      <td>1080_IWL_ANG_XX_augmented_training_V1_6448.wav</td>\n",
       "      <td>augmented_training_samples/1080_IWL_ANG_XX_aug...</td>\n",
       "      <td>male</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>1071_IEO_ANG_MD_augmented_training_V1_3935.wav</td>\n",
       "      <td>augmented_training_samples/1071_IEO_ANG_MD_aug...</td>\n",
       "      <td>male</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>1008_IEO_ANG_MD_augmented_training_V1_7436.wav</td>\n",
       "      <td>augmented_training_samples/1008_IEO_ANG_MD_aug...</td>\n",
       "      <td>female</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>1060_IWL_ANG_XX_augmented_training_V1_5505.wav</td>\n",
       "      <td>augmented_training_samples/1060_IWL_ANG_XX_aug...</td>\n",
       "      <td>female</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7598 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Filename  \\\n",
       "0        1007_IOM_NEU_XX_augmented_training_V1_1025.wav   \n",
       "1                  DC_n20_augmented_training_V1_243.wav   \n",
       "2        1027_ITS_NEU_XX_augmented_training_V1_5727.wav   \n",
       "3     03-01-02-01-02-01-05_augmented_training_V1_167...   \n",
       "4        1084_IEO_NEU_XX_augmented_training_V1_3757.wav   \n",
       "...                                                 ...   \n",
       "7593     1042_DFA_ANG_XX_augmented_training_V1_5556.wav   \n",
       "7594     1080_IWL_ANG_XX_augmented_training_V1_6448.wav   \n",
       "7595     1071_IEO_ANG_MD_augmented_training_V1_3935.wav   \n",
       "7596     1008_IEO_ANG_MD_augmented_training_V1_7436.wav   \n",
       "7597     1060_IWL_ANG_XX_augmented_training_V1_5505.wav   \n",
       "\n",
       "                                               Filepath  Gender  Emotion  \n",
       "0     augmented_training_samples/1007_IOM_NEU_XX_aug...  female  neutral  \n",
       "1     augmented_training_samples/DC_n20_augmented_tr...    male  neutral  \n",
       "2     augmented_training_samples/1027_ITS_NEU_XX_aug...    male  neutral  \n",
       "3     augmented_training_samples/03-01-02-01-02-01-0...    male  neutral  \n",
       "4     augmented_training_samples/1084_IEO_NEU_XX_aug...  female  neutral  \n",
       "...                                                 ...     ...      ...  \n",
       "7593  augmented_training_samples/1042_DFA_ANG_XX_aug...    male    angry  \n",
       "7594  augmented_training_samples/1080_IWL_ANG_XX_aug...    male    angry  \n",
       "7595  augmented_training_samples/1071_IEO_ANG_MD_aug...    male    angry  \n",
       "7596  augmented_training_samples/1008_IEO_ANG_MD_aug...  female    angry  \n",
       "7597  augmented_training_samples/1060_IWL_ANG_XX_aug...  female    angry  \n",
       "\n",
       "[7598 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1022_IWL_ANG_XX.wav</td>\n",
       "      <td>Data\\speech-emotion-recognition-en\\Crema\\1022_...</td>\n",
       "      <td>male</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003_DFA_ANG_XX.wav</td>\n",
       "      <td>Data\\speech-emotion-recognition-en\\Crema\\1003_...</td>\n",
       "      <td>female</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-01-05-01-01-02-04.wav</td>\n",
       "      <td>Data\\speech-emotion-recognition-en\\Ravdess\\aud...</td>\n",
       "      <td>female</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YAF_kite_angry.wav</td>\n",
       "      <td>Data\\speech-emotion-recognition-en\\Tess\\YAF_an...</td>\n",
       "      <td>female</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OAF_page_angry.wav</td>\n",
       "      <td>Data\\speech-emotion-recognition-en\\Tess\\OAF_an...</td>\n",
       "      <td>female</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>1011_IWL_SAD_XX.wav</td>\n",
       "      <td>Data\\speech-emotion-recognition-en\\Crema\\1011_...</td>\n",
       "      <td>male</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>OAF_thumb_sad.wav</td>\n",
       "      <td>Data\\speech-emotion-recognition-en\\Tess\\OAF_Sa...</td>\n",
       "      <td>female</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>1050_ITH_SAD_XX.wav</td>\n",
       "      <td>Data\\speech-emotion-recognition-en\\Crema\\1050_...</td>\n",
       "      <td>male</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>1089_ITS_SAD_XX.wav</td>\n",
       "      <td>Data\\speech-emotion-recognition-en\\Crema\\1089_...</td>\n",
       "      <td>female</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>1019_TIE_SAD_XX.wav</td>\n",
       "      <td>Data\\speech-emotion-recognition-en\\Crema\\1019_...</td>\n",
       "      <td>male</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1519 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Filename  \\\n",
       "0          1022_IWL_ANG_XX.wav   \n",
       "1          1003_DFA_ANG_XX.wav   \n",
       "2     03-01-05-01-01-02-04.wav   \n",
       "3           YAF_kite_angry.wav   \n",
       "4           OAF_page_angry.wav   \n",
       "...                        ...   \n",
       "1514       1011_IWL_SAD_XX.wav   \n",
       "1515         OAF_thumb_sad.wav   \n",
       "1516       1050_ITH_SAD_XX.wav   \n",
       "1517       1089_ITS_SAD_XX.wav   \n",
       "1518       1019_TIE_SAD_XX.wav   \n",
       "\n",
       "                                               Filepath  Gender Emotion  \n",
       "0     Data\\speech-emotion-recognition-en\\Crema\\1022_...    male   angry  \n",
       "1     Data\\speech-emotion-recognition-en\\Crema\\1003_...  female   angry  \n",
       "2     Data\\speech-emotion-recognition-en\\Ravdess\\aud...  female   angry  \n",
       "3     Data\\speech-emotion-recognition-en\\Tess\\YAF_an...  female   angry  \n",
       "4     Data\\speech-emotion-recognition-en\\Tess\\OAF_an...  female   angry  \n",
       "...                                                 ...     ...     ...  \n",
       "1514  Data\\speech-emotion-recognition-en\\Crema\\1011_...    male     sad  \n",
       "1515  Data\\speech-emotion-recognition-en\\Tess\\OAF_Sa...  female     sad  \n",
       "1516  Data\\speech-emotion-recognition-en\\Crema\\1050_...    male     sad  \n",
       "1517  Data\\speech-emotion-recognition-en\\Crema\\1089_...  female     sad  \n",
       "1518  Data\\speech-emotion-recognition-en\\Crema\\1019_...    male     sad  \n",
       "\n",
       "[1519 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "Mel Spectrogram shape: torch.Size([16, 1, 128, 573])\n",
      "Features shape: torch.Size([16, 302])\n",
      "torch.Size([16, 1, 128, 573])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Construct the model for audio classification\n",
    "\n",
    "# Import packages!\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy\n",
    "import librosa\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchaudio\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utilities import Emotion_Classification_Waveforms\n",
    "from modeling import MelSpec_CNN_Model,Feature_MLP_Model,CombinedModel\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "os.chdir(r'C:\\Users\\Neel Patel\\Documents\\Github Repositories\\PytorchAudio_Emotion_Classifier')\n",
    "\n",
    "#Load metadatas for train,val,test\n",
    "metadata_train = np.load('Data/' + 'training_metadata_no_sur.npy',allow_pickle=True)\n",
    "metadata_val = np.load('Data/' + 'val_metadata_no_sur.npy',allow_pickle=True)\n",
    "#metadata_test = np.load('Data/' + 'test_metadata.npy', allow_pickle=True)\n",
    "\n",
    "#Load HDF5 format files \n",
    "train_hdf5_file = 'Data/training_data_no_sur.hdf5'\n",
    "val_hdf5_file = 'Data/validation_data_no_sur.hdf5'\n",
    "#test_hdf5_file = 'Data/test_data.hdf5'\n",
    "\n",
    "train_metadata_df = pd.DataFrame(metadata_train)\n",
    "val_metadata_df = pd.DataFrame(metadata_val)\n",
    "#test_metadata_df = pd.DataFrame(metadata_test)\n",
    "\n",
    "# Create datasets\n",
    "full_train_dataset = Emotion_Classification_Waveforms(\n",
    "    hdf5_file_path=train_hdf5_file,\n",
    "    metadata_df=train_metadata_df\n",
    ")\n",
    "\n",
    "val_dataset = Emotion_Classification_Waveforms(\n",
    "    hdf5_file_path = val_hdf5_file,\n",
    "    metadata_df=val_metadata_df\n",
    ")\n",
    "\n",
    "# Create DataLoaders for training and validation and testing\n",
    "train_dataloader = DataLoader(full_train_dataset, batch_size=16, shuffle=True, num_workers=4,persistent_workers=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4,persistent_workers=True)\n",
    "\n",
    "\n",
    "for i, batch in tqdm(enumerate(val_dataloader)):\n",
    "    print(f\"Batch {i}:\")\n",
    "    print(f\"Mel Spectrogram shape: {batch['waveform_data']['Mel Spectrogram'].shape}\")\n",
    "    print(f\"Features shape: {batch['waveform_data']['Features'].shape}\")\n",
    "\n",
    "    mel_spec = batch['waveform_data']['Mel Spectrogram']\n",
    "    features = batch['waveform_data']['Features']\n",
    "\n",
    "    labels = batch['emotion']\n",
    "\n",
    "    print(batch['waveform_data']['Mel Spectrogram'].shape)\n",
    "    break\n",
    "    #if torch.isnan(labels).any() or torch.isinf(labels).any():\n",
    "    #     print(f\"NaNs/Infs found in labels at batch {i}\")\n",
    "    #     raise NotImplementedError(f\"You have nans! at batch{i} for in these files {labels}\")\n",
    "    \n",
    "    # if torch.isnan(mel_spec).any() or torch.isinf(mel_spec).any():\n",
    "    #     raise NotImplementedError(f\"You have nans! at batch{i} for in these files {batch['filename']}\")\n",
    "    #     #print(\"Found NaN or Inf in Mel Spectrogram!\")\n",
    "    # if torch.isnan(features).any() or torch.isinf(features).any():\n",
    "    #     raise NotImplementedError(f\"You have nans! at batch{i} for in these files {batch['filename']}\")\n",
    "    #     #print(\"Found NaN or Inf in Features!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mel Spectrogram: [[[0.0328729  0.01947049 0.00231159 ... 0.         0.         0.        ]\n",
      "  [0.03935537 0.02577184 0.0074062  ... 0.         0.         0.        ]\n",
      "  [0.09875096 0.08533566 0.05752949 ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.00170687 0.00156399 0.00125927 ... 0.         0.         0.        ]\n",
      "  [0.00110118 0.00104161 0.00093399 ... 0.         0.         0.        ]\n",
      "  [0.00125739 0.00134854 0.00133952 ... 0.         0.         0.        ]]]\n",
      "Features: [-2.20388718e+02  1.01122417e+01  7.25783539e+00  1.42866349e+00\n",
      " -1.56546221e+01 -1.22359447e+01 -1.16007626e+00 -3.86246037e+00\n",
      " -8.11057854e+00  1.48686266e+00 -5.73151731e+00  2.94954985e-01\n",
      " -2.33529472e+00  1.21093750e-01  2.41699219e-01  3.94531250e-01\n",
      "  5.25878906e-01  6.45019531e-01  7.25097656e-01  7.70507812e-01\n",
      "  7.83691406e-01  7.89550781e-01  7.82226562e-01  7.77832031e-01\n",
      "  7.73925781e-01  6.19628906e-01  4.63378906e-01  3.17382812e-01\n",
      "  1.76757812e-01  1.79199219e-01  1.83593750e-01  1.68457031e-01\n",
      "  1.46972656e-01  1.27929688e-01  1.09863281e-01  9.71679688e-02\n",
      "  9.42382812e-02  9.03320312e-02  9.86328125e-02  9.22851562e-02\n",
      "  7.51953125e-02  6.34765625e-02  5.12695312e-02  7.91015625e-02\n",
      "  9.47265625e-02  1.14257812e-01  1.16699219e-01  8.54492188e-02\n",
      "  6.83593750e-02  4.58984375e-02  3.02734375e-02  2.29492188e-02\n",
      "  2.14843750e-02  2.05078125e-02  2.39257812e-02  2.68554688e-02\n",
      "  3.02734375e-02  3.56445312e-02  3.85742188e-02  4.05273438e-02\n",
      "  4.63867188e-02  4.78515625e-02  5.02929688e-02  6.39648438e-02\n",
      "  7.08007812e-02  8.05664062e-02  8.59375000e-02  8.39843750e-02\n",
      "  7.86132812e-02  6.25000000e-02  5.02929688e-02  6.05468750e-02\n",
      "  9.42382812e-02  1.19628906e-01  1.36230469e-01  1.42089844e-01\n",
      "  1.34277344e-01  1.51367188e-01  1.84570312e-01  2.29003906e-01\n",
      "  2.47070312e-01  2.40722656e-01  2.42187500e-01  2.16308594e-01\n",
      "  1.78710938e-01  1.52343750e-01  1.07910156e-01  6.59179688e-02\n",
      "  5.66406250e-02  5.17578125e-02  5.07812500e-02  4.68750000e-02\n",
      "  4.58984375e-02  5.17578125e-02  5.17578125e-02  5.61523438e-02\n",
      "  5.51757812e-02  5.17578125e-02  5.32226562e-02  5.81054688e-02\n",
      "  6.05468750e-02  6.39648438e-02  6.29882812e-02  7.22656250e-02\n",
      "  8.88671875e-02  8.83789062e-02  7.37304688e-02  4.58984375e-02\n",
      "  1.56250000e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.97502878e-03  7.22771371e-03\n",
      "  2.17980016e-02  2.77669039e-02  3.14657316e-02  3.39056030e-02\n",
      "  3.24050523e-02  3.23134810e-02  3.36369649e-02  3.43692377e-02\n",
      "  3.28102969e-02  3.33692171e-02  3.80971096e-02  7.21625835e-02\n",
      "  8.85986909e-02  9.91714969e-02  1.05053239e-01  9.20533761e-02\n",
      "  8.37779567e-02  8.00850242e-02  8.08402672e-02  8.41073990e-02\n",
      "  8.42394307e-02  7.88413659e-02  6.98140413e-02  5.70399202e-02\n",
      "  4.41353396e-02  3.45991366e-02  2.47865859e-02  1.62612386e-02\n",
      "  1.46926884e-02  3.02708726e-02  4.32231724e-02  5.31103313e-02\n",
      "  5.83068393e-02  5.40436022e-02  4.57745530e-02  3.53982449e-02\n",
      "  2.68656444e-02  2.29099616e-02  2.15929262e-02  2.17504315e-02\n",
      "  3.22409198e-02  4.38820906e-02  4.95159589e-02  5.24168275e-02\n",
      "  4.89691272e-02  4.16258536e-02  3.84273604e-02  3.98639888e-02\n",
      "  4.68399078e-02  5.40911183e-02  5.63252531e-02  5.56278713e-02\n",
      "  4.97537889e-02  3.96213904e-02  3.13410498e-02  2.28633117e-02\n",
      "  1.41152842e-02  7.06751365e-03  2.91967741e-03  1.14745589e-03\n",
      "  8.14687985e-04  8.36817315e-04  8.28066142e-04  7.47596438e-04\n",
      "  6.69302070e-04  6.20862877e-04  7.71391089e-04  1.04313053e-03\n",
      "  1.63091510e-03  3.76419467e-03  7.70073617e-03  1.54089676e-02\n",
      "  2.02936660e-02  2.46080607e-02  2.78541353e-02  2.89404206e-02\n",
      "  3.11242174e-02  3.18665504e-02  3.16677578e-02  3.39521505e-02\n",
      "  3.22469659e-02  3.05329878e-02  2.84478627e-02  2.16470156e-02\n",
      "  1.70026887e-02  1.26946354e-02  9.36947577e-03  6.29227515e-03\n",
      "  5.03364578e-03  3.00406199e-03  1.53351517e-03  9.61078971e-04\n",
      "  6.03254244e-04  3.56079574e-04  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File('Data/training_data_no_sur.hdf5', 'r') as hdf:\n",
    "    mel_spec = hdf['mel_spectrograms'][7306]\n",
    "    features = hdf['features'][7306]\n",
    "\n",
    "print(f\"Mel Spectrogram: {mel_spec}\")\n",
    "print(f\"Features: {features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_training_samples/YAF_hole_angry_augmented_training_V1_1081.wav\n",
      "MFCC: tensor([[-122.9263,   15.1686,   10.6831,    1.9926,  -24.1162,  -18.7849,\n",
      "           -1.8305,   -5.8688,  -12.3965,    2.3329,   -8.7366,    0.5298,\n",
      "           -3.5394]])\n",
      "ZCR: tensor([0.1211, 0.2417, 0.3945, 0.5259, 0.6450, 0.7251, 0.7705, 0.7837, 0.7896,\n",
      "        0.7822, 0.7778, 0.7739, 0.6196, 0.4634, 0.3174, 0.1768, 0.1792, 0.1836,\n",
      "        0.1685, 0.1470, 0.1279, 0.1099, 0.0972, 0.0942, 0.0903, 0.0986, 0.0923,\n",
      "        0.0752, 0.0635, 0.0513, 0.0791, 0.0947, 0.1143, 0.1167, 0.0854, 0.0684,\n",
      "        0.0459, 0.0303, 0.0229, 0.0215, 0.0205, 0.0239, 0.0269, 0.0303, 0.0356,\n",
      "        0.0386, 0.0405, 0.0464, 0.0479, 0.0503, 0.0640, 0.0708, 0.0806, 0.0859,\n",
      "        0.0840, 0.0786, 0.0625, 0.0503, 0.0605, 0.0942, 0.1196, 0.1362, 0.1421,\n",
      "        0.1343, 0.1514, 0.1846, 0.2290, 0.2471, 0.2407, 0.2422, 0.2163, 0.1787,\n",
      "        0.1523, 0.1079, 0.0659, 0.0566, 0.0518, 0.0508, 0.0469, 0.0459, 0.0518,\n",
      "        0.0518, 0.0562, 0.0552, 0.0518, 0.0532, 0.0581, 0.0605, 0.0640, 0.0630,\n",
      "        0.0723, 0.0889, 0.0884, 0.0737], device='cuda:0')\n",
      "HNR: tensor([0.], device='cuda:0')\n",
      "RMS: tensor([0.0020, 0.0072, 0.0218, 0.0278, 0.0315, 0.0339, 0.0324, 0.0323, 0.0336,\n",
      "        0.0344, 0.0328, 0.0334, 0.0381, 0.0722, 0.0886, 0.0992, 0.1051, 0.0921,\n",
      "        0.0838, 0.0801, 0.0808, 0.0841, 0.0842, 0.0788, 0.0698, 0.0570, 0.0441,\n",
      "        0.0346, 0.0248, 0.0163, 0.0147, 0.0303, 0.0432, 0.0531, 0.0583, 0.0540,\n",
      "        0.0458, 0.0354, 0.0269, 0.0229, 0.0216, 0.0218, 0.0322, 0.0439, 0.0495,\n",
      "        0.0524, 0.0490, 0.0416, 0.0384, 0.0399, 0.0468, 0.0541, 0.0563, 0.0556,\n",
      "        0.0498, 0.0396, 0.0313, 0.0229, 0.0141, 0.0071, 0.0029, 0.0011, 0.0008,\n",
      "        0.0008, 0.0008, 0.0007, 0.0007, 0.0006, 0.0008, 0.0010, 0.0016, 0.0038,\n",
      "        0.0077, 0.0154, 0.0203, 0.0246, 0.0279, 0.0289, 0.0311, 0.0319, 0.0317,\n",
      "        0.0340, 0.0322, 0.0305, 0.0284, 0.0216, 0.0170, 0.0127, 0.0094, 0.0063,\n",
      "        0.0050, 0.0030, 0.0015, 0.0010], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.getcwd()\n",
    "file_path = train_metadata_df.iloc[7306]['Filepath']\n",
    "print(file_path)\n",
    "waveform, sample_rate = torchaudio.load(r'Data/metadata-and-augmentations/'+file_path)\n",
    "\n",
    "from utilities import extract_hnr,extract_mel_spectrogram,extract_mfcc,extract_rms,extract_zero_crossing_rate\n",
    "from utilities import load_dataset\n",
    "\n",
    "# Process waveform to extract features\n",
    "mfcc = extract_mfcc(waveform)\n",
    "zcr = extract_zero_crossing_rate(waveform)\n",
    "hnr = extract_hnr(waveform)\n",
    "rms = extract_rms(waveform)\n",
    "\n",
    "print(f\"MFCC: {mfcc}\")\n",
    "print(f\"ZCR: {zcr}\")\n",
    "print(f\"HNR: {hnr}\")\n",
    "print(f\"RMS: {rms}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System PATH environment variable:\n",
      "['c:\\\\Users\\\\Neel Patel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311', 'c:\\\\Users\\\\Neel Patel\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\Scripts', 'C:\\\\Program Files\\\\Oculus\\\\Support\\\\oculus-runtime', 'C:\\\\Windows\\\\system32', 'C:\\\\Windows', 'C:\\\\Windows\\\\System32\\\\Wbem', 'C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\', 'C:\\\\Windows\\\\System32\\\\OpenSSH\\\\', 'C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA NvDLISR', 'C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common', 'C:\\\\Program Files\\\\Microsoft SQL Server\\\\Client SDK\\\\ODBC\\\\170\\\\Tools\\\\Binn\\\\', 'C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\150\\\\Tools\\\\Binn\\\\', 'C:\\\\Program Files\\\\Microsoft SQL Server\\\\150\\\\Tools\\\\Binn\\\\', 'C:\\\\Program Files\\\\Microsoft SQL Server\\\\150\\\\DTS\\\\Binn\\\\', 'C:\\\\Program Files (x86)\\\\Windows Kits\\\\8.1\\\\Windows Performance Toolkit\\\\', 'C:\\\\Program Files\\\\MATLAB\\\\R2022b\\\\bin', 'C:\\\\WINDOWS\\\\system32', 'C:\\\\WINDOWS', 'C:\\\\WINDOWS\\\\System32\\\\Wbem', 'C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\', 'C:\\\\WINDOWS\\\\System32\\\\OpenSSH\\\\', 'C:\\\\Program Files\\\\Git\\\\cmd', 'C:\\\\Users\\\\Neel Patel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Scripts\\\\', 'C:\\\\Users\\\\Neel Patel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\', 'C:\\\\Users\\\\Neel Patel\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps', 'C:\\\\Users\\\\Neel Patel\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin', 'C:\\\\Users\\\\Neel Patel\\\\AppData\\\\Roaming\\\\TinyTeX\\\\bin\\\\windows', 'C:\\\\Users\\\\Neel Patel\\\\AppData\\\\Local\\\\GitHubDesktop\\\\bin', 'C:\\\\SQLite', '', 'C:\\\\Program Files\\\\Oculus\\\\Support\\\\oculus-runtime', 'C:\\\\Windows\\\\system32', 'C:\\\\Windows', 'C:\\\\Windows\\\\System32\\\\Wbem', 'C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\', 'C:\\\\Windows\\\\System32\\\\OpenSSH\\\\', 'C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA NvDLISR', 'C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common', 'C:\\\\Program Files\\\\Microsoft SQL Server\\\\Client SDK\\\\ODBC\\\\170\\\\Tools\\\\Binn\\\\', 'C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\150\\\\Tools\\\\Binn\\\\', 'C:\\\\Program Files\\\\Microsoft SQL Server\\\\150\\\\Tools\\\\Binn\\\\', 'C:\\\\Program Files\\\\Microsoft SQL Server\\\\150\\\\DTS\\\\Binn\\\\', 'C:\\\\Program Files (x86)\\\\Windows Kits\\\\8.1\\\\Windows Performance Toolkit\\\\', 'C:\\\\Program Files\\\\MATLAB\\\\R2022b\\\\bin', 'C:\\\\WINDOWS\\\\system32', 'C:\\\\WINDOWS', 'C:\\\\WINDOWS\\\\System32\\\\Wbem', 'C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\', 'C:\\\\WINDOWS\\\\System32\\\\OpenSSH\\\\', 'C:\\\\Program Files\\\\Git\\\\cmd', 'C:\\\\Users\\\\Neel Patel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Scripts\\\\', 'C:\\\\Users\\\\Neel Patel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\', 'C:\\\\Users\\\\Neel Patel\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps', 'C:\\\\Users\\\\Neel Patel\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin', 'C:\\\\Users\\\\Neel Patel\\\\AppData\\\\Roaming\\\\TinyTeX\\\\bin\\\\windows', 'C:\\\\Users\\\\Neel Patel\\\\AppData\\\\Local\\\\GitHubDesktop\\\\bin', 'C:\\\\SQLite', '']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the PATH environment variable\n",
    "print(\"System PATH environment variable:\")\n",
    "print(list(os.environ['PATH'].split(';')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
